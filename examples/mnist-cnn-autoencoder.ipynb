{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN Autoencoder Example\n",
    "Uses Conv2D and Deconv2D operations to create a simple auto-encoder. In this example, it is possible that it learns the trivial function. It's intention is more to see how the *tt.network.conv2d_transpose()* function works.\n",
    "\n",
    "An image scale of [0, 1] is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Force matplotlib to use inline rendering\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FRAME_W_H = 28\n",
    "BATCH_SIZE = 64\n",
    "MAX_STEPS = 500\n",
    "LEARNING_RATE = 1e-3\n",
    "REG = 5e-4\n",
    "\n",
    "TRAIN_ON_BINARY_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt.hardware.set_cuda_devices([1])\n",
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    x  = tf.placeholder(tf.float32, [BATCH_SIZE, FRAME_W_H ** 2], \"X\")\n",
    "    y_ = tf.placeholder(tf.float32, [BATCH_SIZE, FRAME_W_H ** 2], \"Y_\")\n",
    "\n",
    "    x_image = tf.reshape(x, [-1, FRAME_W_H, FRAME_W_H, 1])\n",
    "\n",
    "    with tf.variable_scope(\"Encoder\"):\n",
    "        # 1: Conv\n",
    "        conv1 = tt.network.conv2d(\"Conv1\", x_image,\n",
    "                                  4, (3, 3), (2, 2),\n",
    "                                  weight_init=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                  bias_init=0.1,\n",
    "                                  regularizer=tf.contrib.layers.l2_regularizer(REG),\n",
    "                                  activation=tf.nn.relu)\n",
    "\n",
    "        # 2: Conv\n",
    "        conv2 = tt.network.conv2d(\"Conv2\", conv1,\n",
    "                                  8, (3, 3), (2, 2),\n",
    "                                  weight_init=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                  bias_init=0.1,\n",
    "                                  regularizer=tf.contrib.layers.l2_regularizer(REG),\n",
    "                                  activation=tf.nn.relu)\n",
    "        encoder_out = conv2\n",
    "\n",
    "    with tf.variable_scope(\"Decoder\"):\n",
    "        # 3: Deconv\n",
    "        conv3t = tt.network.conv2d_transpose(\"Deconv1\", encoder_out,\n",
    "                                             8, (3, 3), (2, 2),\n",
    "                                             weight_init=tt.init.bilinear_initializer(),\n",
    "                                             bias_init=0.1,\n",
    "                                             regularizer=tf.contrib.layers.l2_regularizer(REG),\n",
    "                                             activation=tf.nn.relu)\n",
    "\n",
    "        # 4: Deconv\n",
    "        conv4t = tt.network.conv2d_transpose(\"Deconv2\", conv3t,\n",
    "                                             1, (3, 3), (2, 2),\n",
    "                                             weight_init=tt.init.bilinear_initializer(), \n",
    "                                             bias_init=0.1,\n",
    "                                             regularizer=tf.contrib.layers.l2_regularizer(REG),\n",
    "                                             activation=tf.nn.relu) # no activation and relu work better here\n",
    "        decoder_out = conv4t\n",
    "\n",
    "    output = tf.reshape(decoder_out, [-1,FRAME_W_H ** 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    with tf.name_scope(\"Train\"), tf.device('/gpu:0'):\n",
    "        x_image = tf.reshape(output, [-1, FRAME_W_H, FRAME_W_H, 1])\n",
    "        y_image = tf.reshape(y_, [-1, FRAME_W_H, FRAME_W_H, 1])\n",
    "        \n",
    "        # BCE\n",
    "        bce = tt.loss.bce(x_image, y_image)\n",
    "        ms_ssim = tt.loss.ms_ssim(x_image, y_image, patch_size=7, level_weights=[0.25, 0.75])\n",
    "        alpha = 0.84\n",
    "        #loss = (1-alpha) * bce + alpha * ms_ssim + tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "        loss = bce\n",
    "        train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "    sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_binary(data):\n",
    "    d = data.copy()\n",
    "    d[d > 0.5] = 1.0\n",
    "    d[d <= 0.5] = 0.0\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    for i in range(MAX_STEPS + 1):\n",
    "        batch_images, _ = mnist.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        if TRAIN_ON_BINARY_DATA:\n",
    "            batch_images = as_binary(batch_images)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            train_loss = loss.eval(feed_dict={\n",
    "                                   x: batch_images,\n",
    "                                   y_: batch_images})\n",
    "            print(\"step %d / %d, loss %g\" % (i, MAX_STEPS, train_loss))\n",
    "\n",
    "        train_step.run(feed_dict={x: batch_images, y_: batch_images})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show(images, title):\n",
    "    print(\"### {} ###\".format(title))\n",
    "    print (\"Value range: [{}, {}] with avg {}\".format(images.min(), images.max(), images.mean()))\n",
    "    print(\"test loss: %g\" % loss.eval(feed_dict={\n",
    "                                     x: images,\n",
    "                                     y_: images}))\n",
    "    print(\"test BCE (w/o reg): %g\" % bce.eval(feed_dict={\n",
    "                                                        x: images,\n",
    "                                                        y_: images}))\n",
    "    print(\"test MS-SSIM (w/o reg): %g\" % ms_ssim.eval(feed_dict={\n",
    "                                                          x: images,\n",
    "                                                          y_: images}))\n",
    "\n",
    "test_images = mnist.test.images[:BATCH_SIZE]\n",
    "print (\"Value range: [{}, {}]\".format(test_images.min(), test_images.max()))\n",
    "test_images_binary = as_binary(test_images)\n",
    "\n",
    "show(test_images, \"Float\")\n",
    "show(test_images_binary, \"Binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_visualization(images, title):\n",
    "    out_images = output.eval(feed_dict={x: images})\n",
    "    reshaped_images = np.reshape(images, [-1, FRAME_W_H, FRAME_W_H, 1])\n",
    "    tt.visualization.display_batch(reshaped_images * 255, 4, 4, title+\"-GT\")\n",
    "    \n",
    "    reshaped_out_images = np.reshape(out_images, [-1, FRAME_W_H, FRAME_W_H, 1])\n",
    "    tt.visualization.display_batch(reshaped_out_images * 255, 4, 4, title + \"-Reconstr.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_visualization(test_images, \"Float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_visualization(test_images_binary, \"Binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
