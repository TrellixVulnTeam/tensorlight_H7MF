{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST LSTM Example\n",
    "Adapted from [github: TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb).\n",
    "\n",
    "To classify images using a reccurent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow.models.rnn import rnn, rnn_cell\n",
    "import tensortools as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_EXAMPES = 100000\n",
    "DROPOUT = 0.5\n",
    "REG = 5e-4\n",
    "LEARGNING_RATE = 0.001\n",
    "DISPLAY_STEP = 10\n",
    "N_INPUT = 28\n",
    "N_STEPS = 28\n",
    "N_HIDDEN = 128\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, N_INPUT])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(0, N_STEPS, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(N_HIDDEN,\n",
    "                                             forget_bias=1.0,\n",
    "                                             state_is_tuple=True)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.nn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, [None, N_STEPS, N_INPUT], \"X\")\n",
    "    y_ = tf.placeholder(tf.float32, [None, N_CLASSES], \"Y_\")\n",
    "\n",
    "    weights = tf.get_variable(\"weights\",\n",
    "                    shape=[N_HIDDEN, N_CLASSES],\n",
    "                    dtype=tf.float32,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(\"biases\",\n",
    "                    shape=[N_CLASSES])\n",
    "\n",
    "    pred = RNN(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    with tf.name_scope(\"Train\"):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y_))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=LEARGNING_RATE).minimize(cost)\n",
    "\n",
    "    with tf.name_scope(\"Accuracy\"):\n",
    "        correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y_,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        tt.visualization.show_graph(sess.graph_def)\n",
    "        \n",
    "        step = 1\n",
    "        # Keep training until reach max iterations\n",
    "        while step * BATCH_SIZE < NUM_EXAMPES:\n",
    "            batch_x, batch_y = mnist.train.next_batch(BATCH_SIZE)\n",
    "            # Reshape data to get 28 seq of 28 elements\n",
    "            batch_x = batch_x.reshape((BATCH_SIZE, N_STEPS, N_INPUT))\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y_: batch_y})\n",
    "            if step % DISPLAY_STEP == 0:\n",
    "                # Calculate batch accuracy\n",
    "                acc = sess.run(accuracy, feed_dict={x: batch_x, y_: batch_y})\n",
    "                # Calculate batch loss\n",
    "                loss = sess.run(cost, feed_dict={x: batch_x, y_: batch_y})\n",
    "                print \"Iter \" + str(step*BATCH_SIZE) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc)\n",
    "            step += 1\n",
    "        print \"Optimization Finished!\"\n",
    "\n",
    "        # Calculate accuracy for 128 mnist test images\n",
    "        test_len = 128\n",
    "        test_data = mnist.test.images[:test_len].reshape((-1, N_STEPS, N_INPUT))\n",
    "        test_label = mnist.test.labels[:test_len]\n",
    "        print \"Testing Accuracy:\", \\\n",
    "            sess.run(accuracy, feed_dict={x: test_data, y_: test_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
