{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime MNIST CNN Autoencoder Example\n",
    "Uses Conv2D and Deconv2D operations to create a simple auto-encoder. In this example, it is possible that it learns the trivial function. It's intention is more to see how the *tt.network.conv2d_transpose()* function works.\n",
    "\n",
    "An image scale of [0, 1] is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Force matplotlib to use inline rendering\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "REG_LAMBDA = 1e-8\n",
    "INITIAL_LR = 0.01\n",
    "LR_DECAY_STEP_INTERVAL = 10000\n",
    "LR_DECAY_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/work/sauterme/data\"\n",
    "dataset_train = tt.datasets.mnist.MNISTTrainDataset(DATA_ROOT)\n",
    "dataset_valid = tt.datasets.mnist.MNISTValidDataset(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_BN = False\n",
    "ENC_BN = False\n",
    "DEC_BN = False\n",
    "\n",
    "class SimpleCNNAutoencoderModel(tt.model.AbstractModel):    \n",
    "    def __init__(self, reg_lambda=0.0):\n",
    "        super(SimpleCNNAutoencoderModel, self).__init__(reg_lambda)\n",
    "        \n",
    "    @tt.utils.attr.override\n",
    "    def inference(self, inputs, targets, feeds,\n",
    "                  is_training, device_scope, memory_device):\n",
    "        \n",
    "        if INPUT_BN:\n",
    "            inputs = tf.contrib.layers.batch_norm(inputs)\n",
    "        \n",
    "        with tf.variable_scope(\"Encoder\"):\n",
    "            # 1: Conv\n",
    "            conv1 = tt.network.conv2d(\"Conv1\", inputs,\n",
    "                                      8, (5, 5), (2, 2),\n",
    "                                      weight_init=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                      bias_init=-0.1,\n",
    "                                      regularizer=tf.contrib.layers.l2_regularizer(self.reg_lambda),\n",
    "                                      activation=tf.nn.relu)\n",
    "            \n",
    "            if ENC_BN:\n",
    "                conv1 = tf.contrib.layers.batch_norm(conv1)\n",
    "\n",
    "            # 2: Conv\n",
    "            conv2 = tt.network.conv2d(\"Conv2\", conv1,\n",
    "                                      16, (3, 3), (2, 2),\n",
    "                                      weight_init=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                      bias_init=-0.1,\n",
    "                                      regularizer=tf.contrib.layers.l2_regularizer(self.reg_lambda),\n",
    "                                      activation=tf.nn.relu)\n",
    "            \n",
    "            if ENC_BN:\n",
    "                conv2 = tf.contrib.layers.batch_norm(conv2)\n",
    "            \n",
    "            encoder_out = conv2\n",
    "\n",
    "        with tf.variable_scope(\"Decoder\"):\n",
    "            # 3: Deconv\n",
    "            conv3t = tt.network.conv2d_transpose(\"Deconv1\", encoder_out,\n",
    "                                                 8, (3, 3), (2, 2),\n",
    "                                                 weight_init=tt.init.bilinear_initializer(),\n",
    "                                                 bias_init=-0.1,\n",
    "                                                 regularizer=tf.contrib.layers.l2_regularizer(self.reg_lambda),\n",
    "                                                 activation=tf.nn.relu)\n",
    "            \n",
    "            if DEC_BN:\n",
    "                conv3t = tf.contrib.layers.batch_norm(conv3t)\n",
    "\n",
    "            # 4: Deconv\n",
    "            conv4t = tt.network.conv2d_transpose(\"Deconv2\", conv3t,\n",
    "                                                 1, (5, 5), (2, 2),\n",
    "                                                 weight_init=tt.init.bilinear_initializer(), \n",
    "                                                 bias_init=-0.1,\n",
    "                                                 regularizer=tf.contrib.layers.l2_regularizer(self.reg_lambda),\n",
    "                                                 activation=tf.nn.sigmoid)\n",
    "            decoder_out = conv4t\n",
    "            \n",
    "        return decoder_out\n",
    "    \n",
    "    @tt.utils.attr.override\n",
    "    def loss(self, predictions, targets, device_scope):\n",
    "        return tt.loss.bce(predictions, targets) + tt.loss.mgdl(predictions, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tt.hardware.set_cuda_devices([0])\n",
    "runtime = tt.core.DefaultRuntime()\n",
    "runtime.register_datasets(dataset_train, dataset_valid, None)\n",
    "runtime.register_model(SimpleCNNAutoencoderModel(reg_lambda=REG_LAMBDA))\n",
    "runtime.build(INITIAL_LR,\n",
    "              LR_DECAY_STEP_INTERVAL,\n",
    "              LR_DECAY_FACTOR,\n",
    "              is_autoencoder=True,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.train(batch_size=BATCH_SIZE, steps=1000, display_step=50, do_checkpoints=False, do_summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, _ = dataset_valid.get_batch(4)\n",
    "\n",
    "tt.visualization.display_batch(x * 255, nrows=2, ncols=2, title=\"Input\")\n",
    "\n",
    "pred = runtime.predict(x)\n",
    "\n",
    "tt.visualization.display_batch(pred * 255, nrows=2, ncols=2, title=\"Reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.test(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
