{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovingMNIST LSTMConv2D Example\n",
    "Adapted from [github: TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb).\n",
    "\n",
    "Uses a custom LSTM cell that implements the LSTMConv2D op like in Keras. Also, uses an on-the-fly generated MovingMNIST dataset, adapted by [Unsupervised Learning with LSTMs](https://github.com/emansim/unsupervised-videos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Force matplotlib to use inline rendering\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "\n",
    "MAX_STEPS = 500\n",
    "DISPLAY_STEPS = 10\n",
    "VALID_STEPS = 100\n",
    "\n",
    "\n",
    "LEARGNING_RATE = 5e-4\n",
    "\n",
    "TIME_STEPS_IN = 10\n",
    "PREDICTION_STEPS = 1  # this value is more or less hard coded\n",
    "KERNEL_FILTERS = 64\n",
    "KERNEL_SIZE = 5\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 1\n",
    "\n",
    "LSTM_LAYERS = 2\n",
    "\n",
    "REG_LAMBDA = 5e-4\n",
    "\n",
    "MEMORY_DEVICE = '/cpu:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_train = tt.datasets.moving_mnist.MovingMNISTTrainDataset(BATCH_SIZE,\n",
    "                                                                TIME_STEPS_IN + PREDICTION_STEPS)\n",
    "dataset_valid = tt.datasets.moving_mnist.MovingMNISTValidDataset(BATCH_SIZE,\n",
    "                                                                TIME_STEPS_IN + PREDICTION_STEPS)\n",
    "dataset_test = tt.datasets.moving_mnist.MovingMNISTTestDataset(BATCH_SIZE,\n",
    "                                                               TIME_STEPS_IN + PREDICTION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = dataset_train.get_batch()\n",
    "\n",
    "# visualize the first sequence\n",
    "tt.visualization.display_batch(b[0,:,:,:,:], nrows=3, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x):\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2, 3, 4])\n",
    "    # Split to get a list of 'n_steps'\n",
    "    x = tf.split(0, TIME_STEPS_IN, x)\n",
    "    x = [tf.squeeze(i, (0,)) for i in x]\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tt.recurrent.BasicLSTMConv2DCell(KERNEL_SIZE, KERNEL_SIZE, KERNEL_FILTERS,\n",
    "                                                 IMAGE_SIZE, IMAGE_SIZE,\n",
    "                                                 forget_bias=1.0,\n",
    "                                                 hidden_activation=tt.network.hard_sigmoid,\n",
    "                                                 device=MEMORY_DEVICE)\n",
    "    if LSTM_LAYERS > 1:\n",
    "        lstm_cell = tt.recurrent.MultiRNNConv2DCell([lstm_cell] * LSTM_LAYERS,\n",
    "                                                    state_is_tuple=True)\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tt.recurrent.rnn_conv2d(lstm_cell, x)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, [None, TIME_STEPS_IN, IMAGE_SIZE, IMAGE_SIZE, CHANNELS], \"X\")\n",
    "    y_ = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, CHANNELS], \"Y_\")\n",
    "\n",
    "    # image to value scale [-1,1] (roughly zero mean)\n",
    "    x = x * 2 - 1\n",
    "    \n",
    "    out = RNN(x)\n",
    "    \n",
    "    # 1x1 convolution\n",
    "    pred = tt.network.conv2d_transpose(\"Deconv\", out, 1,\n",
    "                             KERNEL_SIZE, KERNEL_SIZE, 1, 1,\n",
    "                             regularizer=tf.contrib.layers.l2_regularizer(REG_LAMBDA),\n",
    "                             device=MEMORY_DEVICE)\n",
    "    \n",
    "    # convert back to value scale [0,1]\n",
    "    pred = (pred + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    with tf.name_scope(\"Train\"):\n",
    "        loss_l2 = tf.nn.l2_loss(pred - y_) / BATCH_SIZE\n",
    "        loss_l1 = tf.reduce_sum(tf.abs(pred - y_)) / BATCH_SIZE\n",
    "        \n",
    "        reg_loss = tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES), name=\"reg_loss\")\n",
    "        total_loss = tf.add(loss_l2, reg_loss, name=\"total_loss\")\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=LEARGNING_RATE).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    # Launch the graph\n",
    "    gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    \n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    tt.visualization.show_graph(sess.graph_def)\n",
    "\n",
    "    dataset_train.reset()\n",
    "    \n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step <= MAX_STEPS:\n",
    "        batch = dataset_train.get_batch()      \n",
    "        batch_x = batch[:,0:TIME_STEPS_IN,:,:,:]\n",
    "        batch_y = batch[:,-1,:,:,:]\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y_: batch_y})\n",
    "        if step % DISPLAY_STEPS == 0:\n",
    "            # Calculate batch loss\n",
    "            l1, l2 = sess.run([loss_l1, loss_l2], feed_dict={x: batch_x, y_: batch_y})\n",
    "            print(\"@{}/{}: Minibatch Train Loss-L2= {:.6f} (Train Loss-L1= {:.6f})\".format(\n",
    "                    step, MAX_STEPS,\n",
    "                    l2, l1))\n",
    "        if step % VALID_STEPS == 0:\n",
    "            dataset_valid.reset()\n",
    "            num_batches = dataset_valid.dataset_size // dataset_valid.batch_size\n",
    "            loss_sum = 0\n",
    "            for b in xrange(num_batches):\n",
    "                batch = dataset_valid.get_batch()\n",
    "                batch_x = batch[:,0:TIME_STEPS_IN,:,:,:]\n",
    "                batch_y = batch[:,-1,:,:,:]\n",
    "                l2 = sess.run(loss_l2, feed_dict={x: batch_x, y_: batch_y})\n",
    "                loss_sum += l2 / PREDICTION_STEPS\n",
    "            \n",
    "            avg_loss_per_frame = loss_sum / num_batches\n",
    "            print(\"@{}: Minibatch Avg. Valid Loss-L2 per Frame= {:.6f}\".format(\n",
    "                    step, avg_loss_per_frame))\n",
    "\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    batch = dataset_test.get_batch()\n",
    "        \n",
    "    batch_x = batch[:,0:TIME_STEPS_IN,:,:,:]\n",
    "    batch_y = batch[:,TIME_STEPS_IN,:,:,:]\n",
    "    \n",
    "    # remove batch_dim\n",
    "    batch_x = batch_x[0,:,:,:,:]\n",
    "    batch_y = batch_y[0,:,:,:] \n",
    "    loss_factor = BATCH_SIZE\n",
    "    \n",
    "    print('IN:')\n",
    "    for i in range(TIME_STEPS_IN):\n",
    "        tt.visualization.display_array(batch_x[i] * 255)\n",
    "        \n",
    "    print('TARGET:')\n",
    "    tt.visualization.display_array(batch_y * 255)\n",
    "    \n",
    "    print('PREDICTION:')\n",
    "    batch_x = np.expand_dims(batch_x, axis=0)\n",
    "    batch_y = np.expand_dims(batch_y, axis=0)\n",
    "    prediction, l1, l2 = sess.run([pred, loss_l1, loss_l2], feed_dict={x: batch_x, y_: batch_y})\n",
    "    prediction_squeezed = np.squeeze(prediction, axis=0)\n",
    "    prediction_scaled = prediction_squeezed * 255\n",
    "    tt.visualization.display_array(prediction_scaled)\n",
    "    \n",
    "    print('PREDICTION (fixed):')\n",
    "    np.place(prediction_squeezed, prediction_squeezed > 1, [1])\n",
    "    np.place(prediction_squeezed, prediction_squeezed < 0, [0])\n",
    "    prediction_scaled = prediction_squeezed * 255\n",
    "    tt.visualization.display_array(prediction_scaled)\n",
    "    \n",
    "    print('min-value: ', np.min(prediction_scaled))\n",
    "    print('max-value: ', np.max(prediction_scaled))\n",
    "    print('Test l1-loss:', l1 * loss_factor)\n",
    "    print('Test l2-loss:', l2 * loss_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    dataset_test.reset()\n",
    "    num_batches = dataset_test.dataset_size // dataset_valid.batch_size\n",
    "    print(num_batches)\n",
    "    loss_sum = 0\n",
    "    for b in xrange(num_batches):\n",
    "        batch = dataset_valid.get_batch()\n",
    "        batch_x = batch[:,0:TIME_STEPS_IN,:,:,:]\n",
    "        batch_y = batch[:,TIME_STEPS_IN,:,:,:]\n",
    "        l2 = sess.run(loss_l2, feed_dict={x: batch_x, y_: batch_y})\n",
    "        loss_sum += l2 / PREDICTION_STEPS\n",
    "\n",
    "    avg_loss_per_frame = loss_sum / num_batches\n",
    "    print(\"Avg. Test Loss-L2 per Frame= {:.6f}\".format(avg_loss_per_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
