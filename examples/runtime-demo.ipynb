{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorTools Runtime Demo\n",
    "\n",
    "Demonstrates the usage of the runtime using a simple autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Force matplotlib to use inline rendering\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to libraries for ipython\n",
    "sys.path.append(os.path.expanduser(\"~/libs\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensortools as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "REG_LAMBDA = 5e-4\n",
    "NUM_GPUS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mnist.h5 has already been downloaded.\n",
      "File mnist.h5 has already been downloaded.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tt.datasets.moving_mnist.MovingMNISTTrainDataset(BATCH_SIZE * NUM_GPUS,\n",
    "                                                                 1)\n",
    "dataset_valid = tt.datasets.moving_mnist.MovingMNISTValidDataset(BATCH_SIZE * NUM_GPUS,\n",
    "                                                                 1)\n",
    "#dataset_test = tt.datasets.moving_mnist.MovingMNISTTestDataset(BATCH_SIZE * NUM_GPUS,\n",
    "#                                                               1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleAutoencoderModel(tt.model.AbstractModel):\n",
    "    \"\"\"Simple neuronal autoencoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs, targets, reg_lambda,\n",
    "                 scope=None, is_training=False):\n",
    "        self._scope = scope  # TODO: move to base class (call is device scope?)\n",
    "        self._is_training = is_training  # TODO: move to base class\n",
    "        super(SimpleAutoencoderModel, self).__init__(inputs, targets, reg_lambda)\n",
    "    \n",
    "    @tt.utils.attr.lazy_property\n",
    "    def predictions(self):\n",
    "        x = tf.contrib.layers.flatten(self._inputs)\n",
    "        encoded = tt.network.fc(\"FC_Enc\", x, 64,\n",
    "                                weight_init=tf.contrib.layers.xavier_initializer(),\n",
    "                                bias_init=0.0)\n",
    "        representation = encoded\n",
    "        decoded = tt.network.fc(\"FC_Dec\", representation, self.input_shape[1] * self.input_shape[2] * self.input_shape[3],\n",
    "                                weight_init=tf.contrib.layers.xavier_initializer(),\n",
    "                                bias_init=0.0)\n",
    "        \n",
    "        return tf.reshape(decoded, [-1, 1, self.input_shape[1], self.input_shape[2], self.input_shape[3]])\n",
    "\n",
    "    @tt.utils.attr.lazy_property\n",
    "    def loss(self):\n",
    "        return tt.loss.bce(self.predictions, self._targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime = tt.core.MultiGpuRuntime()\n",
    "runtime.register_datasets(dataset_train, dataset_valid)\n",
    "runtime.register_model(\n",
    "    lambda x, y, scope, is_training : SimpleAutoencoderModel(x, y,\n",
    "                                                             reg_lambda=REG_LAMBDA,\n",
    "                                                             scope=scope,\n",
    "                                                             is_training=is_training))\n",
    "runtime.setup_feeding(tt.core.FEEDING_AUTOENCODER)\n",
    "runtime.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1...\n",
      "@    10: loss:     0.299, total-loss:     0.299 ( 4361.7 examples/sec,  0.01 sec/batch)\n",
      "@    20: loss:     0.218, total-loss:     0.218 ( 4105.4 examples/sec,  0.01 sec/batch)\n",
      "@    30: loss:     0.183, total-loss:     0.183 ( 5442.7 examples/sec,  0.01 sec/batch)\n",
      "@    40: loss:     0.179, total-loss:     0.179 ( 4571.4 examples/sec,  0.01 sec/batch)\n",
      "@    50: loss:     0.169, total-loss:     0.169 ( 4132.6 examples/sec,  0.01 sec/batch)\n",
      "@    60: loss:     0.166, total-loss:     0.166 ( 4716.6 examples/sec,  0.01 sec/batch)\n",
      "@    70: loss:     0.150, total-loss:     0.150 ( 3409.3 examples/sec,  0.01 sec/batch)\n",
      "@    80: loss:     0.151, total-loss:     0.151 ( 4318.1 examples/sec,  0.01 sec/batch)\n",
      "@    90: loss:     0.148, total-loss:     0.148 ( 3768.3 examples/sec,  0.01 sec/batch)\n",
      "@   100: loss:     0.140, total-loss:     0.140 ( 4058.2 examples/sec,  0.01 sec/batch)\n",
      "\n",
      "@   100: Starting validation (batch-size: 48, dataset-size: 10000):\n",
      "9984/9984 [================================] - 1s - loss: 0.1402     \n",
      "\n",
      "@   110: loss:     0.129, total-loss:     0.129 ( 6540.4 examples/sec,  0.01 sec/batch)\n",
      "@   120: loss:     0.136, total-loss:     0.136 ( 3970.9 examples/sec,  0.01 sec/batch)\n",
      "@   130: loss:     0.129, total-loss:     0.129 ( 6059.1 examples/sec,  0.01 sec/batch)\n",
      "@   140: loss:     0.130, total-loss:     0.130 ( 3130.7 examples/sec,  0.02 sec/batch)\n",
      "@   150: loss:     0.131, total-loss:     0.131 ( 3206.8 examples/sec,  0.01 sec/batch)\n",
      "@   160: loss:     0.123, total-loss:     0.123 ( 4785.6 examples/sec,  0.01 sec/batch)\n",
      "@   170: loss:     0.119, total-loss:     0.119 ( 2823.0 examples/sec,  0.02 sec/batch)\n",
      "@   180: loss:     0.122, total-loss:     0.122 ( 4861.2 examples/sec,  0.01 sec/batch)\n",
      "@   190: loss:     0.119, total-loss:     0.119 ( 3465.7 examples/sec,  0.01 sec/batch)\n",
      "@   200: loss:     0.118, total-loss:     0.118 ( 4505.8 examples/sec,  0.01 sec/batch)\n",
      "\n",
      "@   208: Starting validation (batch-size: 48, dataset-size: 10000):\n",
      "9984/9984 [================================] - 1s - loss: 0.1171     \n",
      "\n",
      "Starting epoch 2...\n",
      "@   210: loss:     0.120, total-loss:     0.120 ( 4046.2 examples/sec,  0.01 sec/batch)\n",
      "@   220: loss:     0.127, total-loss:     0.127 ( 4866.6 examples/sec,  0.01 sec/batch)\n",
      "@   230: loss:     0.123, total-loss:     0.123 ( 4877.6 examples/sec,  0.01 sec/batch)\n",
      "@   240: loss:     0.118, total-loss:     0.118 ( 5822.4 examples/sec,  0.01 sec/batch)\n",
      "@   250: loss:     0.119, total-loss:     0.119 ( 3619.9 examples/sec,  0.01 sec/batch)\n",
      "@   260: loss:     0.123, total-loss:     0.123 ( 6409.4 examples/sec,  0.01 sec/batch)\n",
      "@   270: loss:     0.123, total-loss:     0.123 ( 4202.8 examples/sec,  0.01 sec/batch)\n",
      "@   280: loss:     0.109, total-loss:     0.109 ( 3224.7 examples/sec,  0.01 sec/batch)\n",
      "@   290: loss:     0.119, total-loss:     0.119 ( 4908.0 examples/sec,  0.01 sec/batch)\n",
      "@   300: loss:     0.117, total-loss:     0.117 ( 3941.9 examples/sec,  0.01 sec/batch)\n",
      "@   310: loss:     0.112, total-loss:     0.112 ( 6269.7 examples/sec,  0.01 sec/batch)\n",
      "@   320: loss:     0.109, total-loss:     0.109 ( 3737.4 examples/sec,  0.01 sec/batch)\n",
      "@   330: loss:     0.114, total-loss:     0.114 ( 4126.2 examples/sec,  0.01 sec/batch)\n",
      "@   340: loss:     0.100, total-loss:     0.100 ( 5112.9 examples/sec,  0.01 sec/batch)\n",
      "@   350: loss:     0.105, total-loss:     0.105 ( 4578.0 examples/sec,  0.01 sec/batch)\n",
      "@   360: loss:     0.114, total-loss:     0.114 ( 3908.8 examples/sec,  0.01 sec/batch)\n",
      "@   370: loss:     0.093, total-loss:     0.093 ( 4621.6 examples/sec,  0.01 sec/batch)\n",
      "@   380: loss:     0.104, total-loss:     0.104 ( 5426.2 examples/sec,  0.01 sec/batch)\n",
      "@   390: loss:     0.104, total-loss:     0.104 ( 3683.5 examples/sec,  0.01 sec/batch)\n",
      "@   400: loss:     0.118, total-loss:     0.118 ( 4695.3 examples/sec,  0.01 sec/batch)\n",
      "@   410: loss:     0.128, total-loss:     0.128 ( 4868.6 examples/sec,  0.01 sec/batch)\n",
      "\n",
      "@   416: Starting validation (batch-size: 48, dataset-size: 10000):\n",
      "9984/9984 [================================] - 1s - loss: 0.1101     \n",
      "\n",
      "Starting epoch 3...\n",
      "@   420: loss:     0.111, total-loss:     0.111 ( 4049.3 examples/sec,  0.01 sec/batch)\n",
      "@   430: loss:     0.106, total-loss:     0.106 ( 4462.6 examples/sec,  0.01 sec/batch)\n",
      "@   440: loss:     0.102, total-loss:     0.102 ( 3009.8 examples/sec,  0.02 sec/batch)\n",
      "@   450: loss:     0.106, total-loss:     0.106 ( 5925.2 examples/sec,  0.01 sec/batch)\n",
      "@   460: loss:     0.107, total-loss:     0.107 ( 4116.4 examples/sec,  0.01 sec/batch)\n",
      "@   470: loss:     0.106, total-loss:     0.106 ( 5214.5 examples/sec,  0.01 sec/batch)\n",
      "@   480: loss:     0.101, total-loss:     0.101 ( 4723.5 examples/sec,  0.01 sec/batch)\n",
      "@   490: loss:     0.098, total-loss:     0.098 ( 3524.3 examples/sec,  0.01 sec/batch)\n",
      "@   500: loss:     0.099, total-loss:     0.099 ( 3417.4 examples/sec,  0.01 sec/batch)\n",
      "@   510: loss:     0.104, total-loss:     0.104 ( 3491.7 examples/sec,  0.01 sec/batch)\n",
      "@   520: loss:     0.097, total-loss:     0.097 ( 3261.1 examples/sec,  0.01 sec/batch)\n",
      "@   530: loss:     0.099, total-loss:     0.099 ( 4071.6 examples/sec,  0.01 sec/batch)\n",
      "@   540: loss:     0.101, total-loss:     0.101 ( 4425.9 examples/sec,  0.01 sec/batch)\n",
      "@   550: loss:     0.100, total-loss:     0.100 ( 3659.7 examples/sec,  0.01 sec/batch)\n",
      "@   560: loss:     0.100, total-loss:     0.100 ( 4690.3 examples/sec,  0.01 sec/batch)\n",
      "@   570: loss:     0.101, total-loss:     0.101 ( 5600.3 examples/sec,  0.01 sec/batch)\n",
      "@   580: loss:     0.098, total-loss:     0.098 ( 3167.3 examples/sec,  0.02 sec/batch)\n",
      "@   590: loss:     0.098, total-loss:     0.098 ( 4123.0 examples/sec,  0.01 sec/batch)\n",
      "@   600: loss:     0.107, total-loss:     0.107 ( 2972.5 examples/sec,  0.02 sec/batch)\n",
      "@   610: loss:     0.104, total-loss:     0.104 ( 6704.9 examples/sec,  0.01 sec/batch)\n",
      "@   620: loss:     0.101, total-loss:     0.101 ( 3932.8 examples/sec,  0.01 sec/batch)\n",
      "\n",
      "@   624: Starting validation (batch-size: 48, dataset-size: 10000):\n",
      "9984/9984 [================================] - 1s - loss: 0.1038     \n",
      "\n",
      "Starting epoch 4...\n",
      "@   630: loss:     0.108, total-loss:     0.108 ( 4426.8 examples/sec,  0.01 sec/batch)\n",
      "@   640: loss:     0.113, total-loss:     0.113 ( 3786.4 examples/sec,  0.01 sec/batch)\n",
      "@   650: loss:     0.114, total-loss:     0.114 ( 3829.8 examples/sec,  0.01 sec/batch)\n",
      "@   660: loss:     0.111, total-loss:     0.111 ( 4476.4 examples/sec,  0.01 sec/batch)\n",
      "@   670: loss:     0.111, total-loss:     0.111 ( 3796.5 examples/sec,  0.01 sec/batch)\n",
      "@   680: loss:     0.110, total-loss:     0.110 ( 5381.2 examples/sec,  0.01 sec/batch)\n",
      "@   690: loss:     0.106, total-loss:     0.106 ( 5899.7 examples/sec,  0.01 sec/batch)\n",
      "@   700: loss:     0.101, total-loss:     0.101 ( 6311.6 examples/sec,  0.01 sec/batch)\n",
      "@   710: loss:     0.108, total-loss:     0.108 ( 3107.8 examples/sec,  0.02 sec/batch)\n",
      "@   720: loss:     0.108, total-loss:     0.108 ( 5143.0 examples/sec,  0.01 sec/batch)\n",
      "@   730: loss:     0.101, total-loss:     0.101 ( 4153.6 examples/sec,  0.01 sec/batch)\n",
      "@   740: loss:     0.099, total-loss:     0.099 ( 6284.4 examples/sec,  0.01 sec/batch)\n",
      "@   750: loss:     0.105, total-loss:     0.105 ( 3417.6 examples/sec,  0.01 sec/batch)\n",
      "@   760: loss:     0.101, total-loss:     0.101 ( 6219.2 examples/sec,  0.01 sec/batch)\n",
      "@   770: loss:     0.094, total-loss:     0.094 ( 5040.0 examples/sec,  0.01 sec/batch)\n",
      "@   780: loss:     0.106, total-loss:     0.106 ( 5048.4 examples/sec,  0.01 sec/batch)\n",
      "@   790: loss:     0.105, total-loss:     0.105 ( 3452.2 examples/sec,  0.01 sec/batch)\n",
      "@   800: loss:     0.095, total-loss:     0.095 ( 6212.1 examples/sec,  0.01 sec/batch)\n",
      "@   810: loss:     0.103, total-loss:     0.103 ( 6579.1 examples/sec,  0.01 sec/batch)\n",
      "@   820: loss:     0.129, total-loss:     0.129 ( 2736.0 examples/sec,  0.02 sec/batch)\n",
      "@   830: loss:     0.121, total-loss:     0.121 ( 4446.9 examples/sec,  0.01 sec/batch)\n",
      "\n",
      "@   832: Starting validation (batch-size: 48, dataset-size: 10000):\n",
      "9984/9984 [================================] - 1s - loss: 0.1263     \n",
      "\n",
      "Starting epoch 5...\n",
      "@   840: loss:     0.126, total-loss:     0.126 ( 5460.9 examples/sec,  0.01 sec/batch)\n",
      "@   850: loss:     0.134, total-loss:     0.134 ( 3900.2 examples/sec,  0.01 sec/batch)\n",
      "@   860: loss:     0.121, total-loss:     0.121 ( 6589.0 examples/sec,  0.01 sec/batch)\n",
      "@   870: loss:     0.118, total-loss:     0.118 ( 3555.5 examples/sec,  0.01 sec/batch)\n",
      "@   880: loss:     0.111, total-loss:     0.111 ( 6247.5 examples/sec,  0.01 sec/batch)\n",
      "@   890: loss:     0.123, total-loss:     0.123 ( 2999.6 examples/sec,  0.02 sec/batch)\n",
      "@   900: loss:     0.115, total-loss:     0.115 ( 4130.1 examples/sec,  0.01 sec/batch)\n",
      "@   910: loss:     0.111, total-loss:     0.111 ( 5305.6 examples/sec,  0.01 sec/batch)\n",
      "@   920: loss:     0.115, total-loss:     0.115 ( 4514.7 examples/sec,  0.01 sec/batch)\n",
      "@   930: loss:     0.116, total-loss:     0.116 ( 3815.6 examples/sec,  0.01 sec/batch)\n",
      "@   940: loss:     0.110, total-loss:     0.110 ( 2917.6 examples/sec,  0.02 sec/batch)\n",
      "@   950: loss:     0.103, total-loss:     0.103 ( 4571.0 examples/sec,  0.01 sec/batch)\n",
      "@   960: loss:     0.105, total-loss:     0.105 ( 4347.8 examples/sec,  0.01 sec/batch)\n",
      "@   970: loss:     0.103, total-loss:     0.103 ( 5053.3 examples/sec,  0.01 sec/batch)\n",
      "@   980: loss:     0.105, total-loss:     0.105 ( 5776.3 examples/sec,  0.01 sec/batch)\n",
      "@   990: loss:     0.117, total-loss:     0.117 ( 3133.0 examples/sec,  0.02 sec/batch)\n",
      "@  1000: loss:     0.100, total-loss:     0.100 ( 5336.3 examples/sec,  0.01 sec/batch)\n",
      "@  1010: loss:     0.101, total-loss:     0.101 ( 6961.5 examples/sec,  0.01 sec/batch)\n",
      "@  1020: loss:     0.107, total-loss:     0.107 ( 5634.5 examples/sec,  0.01 sec/batch)\n",
      "@  1030: loss:     0.117, total-loss:     0.117 ( 5015.6 examples/sec,  0.01 sec/batch)\n",
      "@  1040: loss:     0.105, total-loss:     0.105 ( 3881.6 examples/sec,  0.01 sec/batch)\n",
      "\n",
      "@  1040: Starting validation (batch-size: 48, dataset-size: 10000):\n",
      "9984/9984 [================================] - 1s - loss: 0.1130     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtime.train(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runtime.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
